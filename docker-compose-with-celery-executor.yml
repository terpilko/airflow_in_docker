version: '3.2'
networks:
  airflow:

volumes:
  volume-postgresql:
    external: true

services:
  postgres:
    image: postgres:13.1
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_DB=airflow
      - POSTGRES_PASSWORD=airflow
      - PGDATA=/var/lib/postgresql/data/pgdata
    ports:
      - 5432:5432
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - volume-postgresql:/var/lib/postgresql/data/pgdata
      - volume-postgresql:/var/lib/postgresql/data/log
    command: >
     postgres
       -c listen_addresses=*
       -c logging_collector=on
       -c log_destination=stderr
       -c max_connections=200
    networks:
      - airflow
  redis:
    image: redis:5.0.5
    environment:
      REDIS_HOST: redis
      REDIS_PORT: 6379
    ports:
      - 6379:6379
    networks:
      - airflow
  webserver:
    env_file:
      - .env
    image: apache/airflow:1.10.15-python3.8-build
    ports:
      - 8080:8080
    volumes:
      - ./dags:/root/airflow/dags
      - ./logs:/root/airflow/logs
      - ./files:/root/airflow/files
      - /var/run/docker.sock:/var/run/docker.sock
    deploy:
      restart_policy:
        condition: on-failure
        delay: 8s
        max_attempts: 3
    depends_on:
      - postgres
      - redis
    command: airflow webserver
    healthcheck:
      test: ["CMD-SHELL", "[ -f /root/airflow/airflow-webserver.pid ]"]
      interval: 30s
      timeout: 30s
      retries: 3
    networks:
      - airflow
  flower:
    image: apache/airflow:1.10.15-python3.8-build
    env_file:
      - .env
    ports:
      - 5555:5555
    depends_on:
      - redis
    deploy:
      restart_policy:
        condition: on-failure
        delay: 8s
        max_attempts: 3
    volumes:
      - ./logs:/root/airflow/logs
    command: airflow flower
    networks:
      - airflow
  scheduler:
    image: apache/airflow:1.10.15-python3.8-build
    env_file:
      - .env
    volumes:
      - ./dags:/root/airflow/dags
      - ./logs:/root/airflow/logs
      - ./files:/root/airflow/files
      - /var/run/docker.sock:/var/run/docker.sock
    command: airflow scheduler
    deploy:
      restart_policy:
        condition: on-failure
        delay: 8s
        max_attempts: 3
    networks:
      - airflow
  worker:
    image: apache/airflow:1.10.15-python3.8-build
    env_file:
      - .env
    volumes:
      - ./dags:/root/airflow/dags
      - ./logs:/root/airflow/logs
      - ./files:/root/airflow/files
      - /var/run/docker.sock:/var/run/docker.sock
    command: airflow worker
    depends_on:
      - scheduler
    
    deploy:
      restart_policy:
        condition: on-failure
        delay: 8s
        max_attempts: 3
    networks:
      - airflow
  initdb:
    image: apache/airflow:1.10.15-python3.8-build
    env_file:
      - .env
    volumes:
      - ./dags:/root/airflow/dags
      - ./logs:/root/airflow/logs
      - ./files:/root/airflow/files
      - /var/run/docker.sock:/var/run/docker.sock
    entrypoint: /bin/bash
    deploy:
      restart_policy:
        condition: on-failure
        delay: 8s
        max_attempts: 5
    command: -c "airflow db init"
    depends_on:
      - redis
      - postgres
    networks:
      - airflow